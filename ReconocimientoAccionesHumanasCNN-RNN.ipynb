{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de acciones humanas\n",
    "\n",
    "Comparar arquitecturas RNN y CNN para reconocimiento de acciones humanas en el conjunto UCF11. La solución debe cumplir con los siguientes puntos:\n",
    "* Usar las características convolucionales vistas en clase (dataset: https://cloud.xibalba.com.mx/s/QwapfBYpYNmNbPP)\n",
    "* Implementar una arquitectura RNN bidireccional con una capa GRU.\n",
    "* Implementar una arquitectura CNN con una capa Conv1d.\n",
    "* Modificar el tamaño de las capas para que ambos modelos tengan un número similar de parámetros.\n",
    "* Discutir el comportamiento durante el entrenamiento y resultados finales en ambos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-summary in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.5)\n",
      "Requirement already satisfied: zarr in c:\\programdata\\anaconda3\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: asciitree in c:\\programdata\\anaconda3\\lib\\site-packages (from zarr) (0.3.3)\n",
      "Requirement already satisfied: numcodecs>=0.6.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from zarr) (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from zarr) (1.17.5)\n",
      "Requirement already satisfied: fasteners in c:\\programdata\\anaconda3\\lib\\site-packages (from zarr) (0.16)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from fasteners->zarr) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-summary\n",
    "!pip install zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26135ae80b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importamos librerias utiles \n",
    "#deep learning\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as optimizerr\n",
    "import torchvision.datasets.utils as tutils\n",
    "import torchvision.datasets as DataSets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torchvision.models as torchModels\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#matrices y matematicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# tomar n elementos de una secuencia\n",
    "from itertools import islice as take\n",
    "#imagenes\n",
    "from matplotlib import pyplot as plt\n",
    "#arreglos multidimensionales\n",
    "import zarr\n",
    "#descarga de archivos\n",
    "import wget\n",
    "#para acceder a ficheros del sistema\n",
    "import os\n",
    "import glob\n",
    "#para descomprimir el archivo UTKFace.tar.gz\n",
    "import tarfile\n",
    "# barra de progreso\n",
    "from tqdm import trange\n",
    "#para reproducibilidad\n",
    "import random\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando cuda:0\n"
     ]
    }
   ],
   "source": [
    "#para usar la GPU si esta disponible\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"\n",
    "\n",
    "device = torch.device(dev)\n",
    "print('Usando {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCF 11: Youtube Action Data Set\n",
    "contiene 11 cantegorias de acciones humanas: basketball shooting, biking or cycling, diving, golf swinging, horse back riding, soccer juggling, swinging, trampoline jumping, volleyball spiking and walking with a dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del dataset en pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCF11(Dataset):\n",
    "    #funcion instanciadora\n",
    "    def __init__(self, directory, download = False):\n",
    "        #definimos variable \"global\" de la clase\n",
    "        self.directory = directory\n",
    "        #definimos el directorio donde estaran los datos, tambien es variable \"global\"\n",
    "        self.zarrDirectory = os.path.join(self.directory, 'ucf11.zarr')\n",
    "        #si download=True\n",
    "        if download:\n",
    "            #aplica el metodo downloadDataset\n",
    "            self.downloadDataset()\n",
    "        #define variable para abrir el los archivos .zarr\n",
    "        self.zar = zarr.open(self.zarrDirectory, 'r')\n",
    "        #lista los directorios contenidos dentro del directorio\n",
    "        self.paths = list(self.zar.array_keys())\n",
    "    #metodo para extraer items del dataset        \n",
    "    def __getitem__(self, idx):\n",
    "        #extrae un elemento contenida dentro del directorio paths con id idx\n",
    "        array = self.zar[self.paths[idx]]\n",
    "        #convierte a matriz el elemento extraido\n",
    "        x = np.array(array)\n",
    "        #extrae su etiqueta\n",
    "        y = np.array(array.attrs['y'], dtype = np.int64)\n",
    "        #regresa la matriz y su etiqueta\n",
    "        return x , y\n",
    "    #metodo para extraer la cantidad de datos en dataset\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    #metodo para descargar los datos\n",
    "    def downloadDataset(self):\n",
    "        #funcioon de pytorch que permite descargar los datos\n",
    "        tutils.download_and_extract_archive(\n",
    "            #url de los datos\n",
    "            url = 'http://cloud.xibalba.com.mx/s/QwapfBYpYNmNbPP/download',\n",
    "            #ruta donde se guardan los datos\n",
    "            download_root = self.directory,\n",
    "            #nombre del archivo a descargar\n",
    "            filename = 'ucf11.zarr.tar.gz'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: dataUCF\\ucf11.zarr.tar.gz\n",
      "Extracting dataUCF\\ucf11.zarr.tar.gz to dataUCF\n",
      "El dataset consta de 1599 muestras\n",
      "Los datos \"duros\" son matrices de dimensiones (10, 1024)\n",
      "Las clases son enteros\n"
     ]
    }
   ],
   "source": [
    "dataset = UCF11('dataUCF', True)\n",
    "print('El dataset consta de {} muestras'.format(len(dataset)))\n",
    "sampleX , sampleY = dataset[499]\n",
    "print('Los datos \"duros\" son matrices de dimensiones {}'.format(sampleX.shape))\n",
    "print('Las clases son enteros')\n",
    "#limpiamos las variables\n",
    "sampleX, sampleY = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La suma de los enteros trainSize y testSize es 1599\n",
      "La suma de la longitud de train y test es 1599\n"
     ]
    }
   ],
   "source": [
    "#definimos el tamaño de los conjuntos de prueba y entrenamiento\n",
    "trainSize = int(0.8 * len(dataset))\n",
    "testSize = int(len(dataset) - trainSize)\n",
    "#hacemos un print para verificar que no se quedaron datos sin asignar\n",
    "print('La suma de los enteros trainSize y testSize es {}'.format(testSize+trainSize))\n",
    "#instanciamos los datasets de entrenamiento y prueba a partir del deataset general shufleado\n",
    "train, test = random_split(dataset, [trainSize ,testSize])\n",
    "#hacemos un print para verificar que no se quedaron datos sin asignar\n",
    "print('La suma de la longitud de train y test es {}'.format(len(test)+len(train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x de train shape=torch.Size([64, 10, 1024]) dtype=torch.float32\n",
      "y de train shape=torch.Size([64]) dtype=torch.int64\n",
      "x de test shape=torch.Size([64, 10, 1024]) dtype=torch.float32\n",
      "y de test shape=torch.Size([64]) dtype=torch.int64\n"
     ]
    }
   ],
   "source": [
    "#creamos el cargador de datos de entrenamiento con un tamaño de lote de 64, se hace shuffle.\n",
    "#no usar otro numero de num_workers de cero porque si no no jala ¿Error de pytorch?\n",
    "trainLoader = DataLoader(train, batch_size=64, shuffle = True, num_workers=0)\n",
    "#creamos el cargador de datos de prueba con un tamaño de lote de 64, se hace shuffle.\n",
    "#no usar otro numero de num_workers de cero porque si no no jala ¿Error de pytorch?\n",
    "testLoader = DataLoader(test, batch_size=64, shuffle = True, num_workers=0)\n",
    "\n",
    "#verificamos que los datos se hayan cargado correctamente\n",
    "x, y = next(iter(trainLoader))\n",
    "print(f'x de train shape={x.shape} dtype={x.dtype}')\n",
    "print(f'y de train shape={y.shape} dtype={y.dtype}')\n",
    "x, y = next(iter(testLoader))\n",
    "print(f'x de test shape={x.shape} dtype={x.dtype}')\n",
    "print(f'y de test shape={y.shape} dtype={y.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la arquitectura RNN-GRU bidireccional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la clase RNN\n",
    "class RNN(nn.Module):\n",
    "    #metodo instanciador, inputSize: longitud de la entrada x. hiddenSize: tamaño\n",
    "    #de las caracteristicas del estado oculto h.\n",
    "    def __init__(self, inputSize=1024, hiddenSize = 128, numClasses = 11):\n",
    "        #instanciamos a la clase padre RNN de pytorch\n",
    "        super(RNN, self).__init__()\n",
    "        self.batchNorm = nn.BatchNorm1d(inputSize)\n",
    "        self.recurrentNN = nn.GRU(input_size=inputSize, hidden_size = hiddenSize, num_layers = 1, \n",
    "                                  batch_first=True, bidirectional=True)\n",
    "        self.classifierN = nn.Linear(hiddenSize, numClasses)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Los datos vienen como [batch, secuencia, caracteristicas] los permutamos a\n",
    "        # [batch, caract, secuencia] para pasarlos por el batchNorm\n",
    "        x = x.permute(0, 2, 1)\n",
    "        #batchnorm\n",
    "        x = self.batchNorm(x)\n",
    "        #repermutamos al estado original\n",
    "        x = x.permute(0, 2, 1)\n",
    "        #RNN escupe la salida out y el estado oculto h_n\n",
    "        x, h = self.recurrentNN(x)\n",
    "        #tiramos a la basura h porque no hay otras RNN conectadas a esta.\n",
    "        #calculamos la media de las salidas (x)\n",
    "        #x = torch.mean(x,1)\n",
    "        x = x[:,-1,:]\n",
    "        #clasificador\n",
    "        x = self.classifierN(x)\n",
    "        #regresa la clasificacion\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchsummary. See above stack traces for more details. Executed layers up to: [BatchNorm1d: 1-1, GRU: 1-2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[1;32m<ipython-input-16-8b41da4d5660>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m#clasificador\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifierN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m#regresa la clasificacion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-c673096a89cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodelRNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodelRNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelRNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mexecuted_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msummary_list\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuted\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    144\u001b[0m                 \u001b[1;34m\"Failed to run torchsummary. See above stack traces for more details. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m                 \u001b[1;34m\"Executed layers up to: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecuted_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchsummary. See above stack traces for more details. Executed layers up to: [BatchNorm1d: 1-1, GRU: 1-2]"
     ]
    }
   ],
   "source": [
    "modelRNN = RNN()\n",
    "modelRNN = modelRNN.to(device)\n",
    "summary(modelRNN, (11, 1024), device = device, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (batchNorm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (recurrentNN): GRU(1024, 128, batch_first=True, bidirectional=True)\n",
       "  (classifierN): Linear(in_features=128, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
